# Literature Review: Systematic review of ChatGPT in higher education-Navigating impact on learning, wellbeing, and collaboration

**Source:** `papers pdf/Systematic review of ChatGPT in higher education-Navigating impact on learning, wellbeing, and collaboration.pdf`  
**Converted:** 2025-11-05 15:15:41  
**Status:** Auto-converted from PDF using PyMuPDF  

---



## Page 1

Review Article
Systematic review of ChatGPT in higher education: Navigating impact on 
learning, wellbeing, and collaboration
Naya Abdallah a, Rateb Katmah b,*
, Kinda Khalaf b,c, Herbert F. Jelinek c,d
a Sarah Lawrence College, Bronxville, NY, USA
b Biomedical Engineering & Biotechnology, Khalifa University, Abu Dhabi, United Arab Emirates
c Health Engineering Innovation Group, Khalifa University, Abu Dhabi, United Arab Emirates
d Medical Sciences, Khalifa University, Abu Dhabi, United Arab Emirates
A R T I C L E  I N F O
Keywords:
ChatGPT
Higher education
Academic performance
Mental health
Student engagement
A B S T R A C T
The rapid evolution of artificial intelligence (AI)-based chatbots has significantly influenced higher education in 
the last couple of years, with large language models (LLMs), such as OpenAI’s ChatGPT, emerging as trans­
formative tools. ChatGPT is actively and widely adopted for academic applications, including tutoring, essay 
drafting, content clarification, and feedback generation. While its integration into educational settings offers 
numerous advantages, from enhancing learning outcomes and reducing test anxiety to fostering engagement and 
collaboration, it raises concerns regarding academic integrity, critical thinking, and over-reliance on AI- 
generated content. This paper presents a systematic review of existing literature on using ChatGPT in higher 
education, following a PRISMA-based methodology to analyze 39 studies published between 2023 and 2024. The 
review synthesizes findings across five key dimensions: academic performance, mental health, second-language 
learners, social influence, and inspiration. The results indicate that while ChatGPT improves accessibility to 
knowledge and provides cognitive and emotional support, its misuse may hinder independent learning and in­
crease technostress. Furthermore, this review explores ethical and policy considerations surrounding ChatGPT’s 
adoption, emphasizing the need for balanced integration strategies. Key recommendations include institutional 
guidelines, AI literacy initiatives, and frameworks for ethical integration. This review offers critical insights for 
educators, policymakers, and researchers seeking to navigate the evolving academic landscape shaped by AI.
1. Introduction
Generative artificial intelligence (AI) is rapidly transforming edu­
cation by reshaping how knowledge is delivered, consumed, and un­
derstood. Among these tools, large language models (LLMs) like 
OpenAI’s ChatGPT have gained prominence for their advanced natural 
language processing (NLP) capabilities. LLMs are AI-based models 
trained on vast datasets, including text, images, and audio using self- 
supervised learning to perform tasks such as language generation, 
translation, and information extraction. Generative Pretrained Trans­
formers (GPTs), in particular, remain the most powerful LLMs due to 
their strength in predicting syntax, semantics, and meaning (AlAfnan 
et al., 2023).
Since GPT-1’s launch in 2018, ChatGPT has improved rapidly, with 
the latest version (GPT-4, 2024) offering better accuracy, alignment 
with user needs, real-time web access, and reduced harmful output 
(Rawas, 2024). Today, ChatGPT supports a range of academic uses, from 
tutoring and essay feedback to summarization and personalized study 
help, redefining traditional learning and promoting inclusive, adaptive 
education. The platform now exceeds 180 million monthly active users. 
Its popularity surged within two months of launch, reaching 100 million 
users, a record-breaking adoption rate (Singh, 2025). This growth re­
flects its intuitive design, cross-disciplinary value, and the rising demand 
for accessible AI tools amid digital transformation in education 
(Michel-Villarreal et al., 2023).
As researchers quickly recognized that the rise of generative AI in 
education is not merely a technological trend but a transformative 
movement, several studies have emerged regarding its impact on 
teaching methodologies, student learning and academic engagement, 
and institutional policies. For instance, Huang et al. (Huang et al., 2023) 
* Corresponding author.
E-mail addresses: nabdallah@gm.slc.edu (N. Abdallah), 100062079@ku.ac.ae (R. Katmah), kinda.khalaf@ku.ac.ae (K. Khalaf), herbert.jelinek@ku.ac.ae
(H.F. Jelinek). 
Contents lists available at ScienceDirect
Social Sciences & Humanities Open
journal homepage: www.sciencedirect.com/journal/social-sciences-and-humanities-open
https://doi.org/10.1016/j.ssaho.2025.101866
Received 30 April 2025; Received in revised form 29 July 2025; Accepted 1 August 2025  
Social Sciences & Humanities Open 12 (2025) 101866 
Available online 4 August 2025 
2590-2911/© 2025 The Authors. Published by Elsevier Ltd. This is an open access article under the CC BY license ( http://creativecommons.org/licenses/by/4.0/ ). 


## Page 2

demonstrated the efficacy of AI-driven personalized interventions in 
improving learning outcomes and self-regulation among students 
enrolled in technical courses, while others expressed concern regarding 
its potential negative impact on the development of critical learning and 
employability 
skills 
in 
undergraduate 
students, 
including 
problem-solving, critical thinking, reasoning, and creativity (Farrokhnia 
et al., 2024). Examining a different aspect relevant to education, yet 
equally critical, several studies found that integrating AI tools into 
learning environments had a significant emotional influence on under­
graduate students, including lessened test anxiety, trust and relief, but 
also disappointment and anxiety regarding false content, as well as 
isolation and loneliness (Acosta-Enriquez et al., 2024; Crawford et al., 
2024; Gao, 2024). Stadler et al. (Stadler et al., 2024) suggested that 
while LLMs reduce cognitive load during academic tasks, they may 
inadvertently promote superficial surface-level learning and reduce the 
quality of reasoning and argumentation. This raises important questions 
about whether convenience and efficiency come at the expense of in­
tellectual rigor.
Beyond cognitive impact, ChatGPT’s adoption is associated with 
various behavioral and psychological implications. Liu et al. (Liu, 2024) 
examined how writing anxiety among English as a Second Language 
(ESL) learners influenced their use of ChatGPT as an automated writing 
tool. Their findings revealed that ChatGPT effectively reduced writing 
anxiety and fostered a positive attitude toward academic writing. 
However, the same study noted that such perceived ease of use could 
lead to complacency in skill development, highlighting the risk of 
over-reliance on AI assistance at the expense of meaningfully acquiring 
and practicing a language. Similarly, Zogheib et al. (Zogheib & Zogheib, 
2024) and Gulati et al. (Gulati et al., 2024) investigated factors influ­
encing the adoption of ChatGPT among students, noting that perceived 
usefulness, ease of use, and trust significantly shaped behavioral in­
tentions. Gulati et al. (Gulati et al., 2024) further emphasized that 
habitual usage was a stronger predictor of adoption than perceived risk, 
suggesting that ChatGPT may become an ingrained part of a student’s 
study habits.
The ethical and equity considerations of ChatGPT adoption must also 
be addressed. While generative AI has the potential to democratize ac­
cess to quality education, disparities in digital literacy, access to tech­
nology, and the biased nonexclusive data currently used in creating 
LLMs may exacerbate existing educational inequities. Furthermore, the 
lack of transparency in AI algorithms and data privacy concerns also 
present major ethical dilemmas, as students and educators continue to 
struggle with issues of trust and accountability. Duong et al. (Duong 
et al., 2024) investigated the "dark side" of ChatGPT usage, concluding 
that compulsive reliance on the tool was associated with increased 
psychological distress, loneliness, and social avoidance. This study 
further identified that technostress exacerbated these effects, acting as a 
moderating factor.
The implications of ChatGPT adoption extend beyond individual 
learners to broader pedagogical practices and institutional policies. 
Sandu et al. (Sandu et al., 2024) conducted a case study in Australian 
higher education, revealing that while ChatGPT enhanced academic 
performance and engagement in data analytics courses by assisting 
students in interpreting complex datasets and generating structured 
responses, it struggled to address complex queries, underscoring the 
need for complementary human guidance. Similarly, Kim et al. (Kim, 
Majdara, & Olson, 2024) explored its use in engineering lab report 
writing, concluding that while ChatGPT improved genre understanding, 
it occasionally generated inaccurate or misleading content, necessitating 
careful supervision.
These findings underscore the complex interplay among the poten­
tial benefits and challenges closely intertwined in association with the 
use of ChatGPT in college students, emphasizing that its foreseen role as 
a positive educational transformation tool must be carefully and prag­
matically examined in the context of current learning agents and envi­
ronments. Whether AI can address key challenges in education, while 
navigating its complex and sometimes conflicting impacts remains 
largely unanswered.
The overlay visualization in Fig. 1 demonstrates the co-occurrence of 
keywords from literature concerning ChatGPT’s significance in higher 
education, particularly with learning, well-being, and collaboration 
during the period 2023–24. The node size denotes the frequency of 
keyword utilization, the edge thickness signifies the strength of co- 
occurrence, and the color gradient (2023–2024) illustrates the chrono­
logical evolution of study themes. Key concepts such as ChatGPT, stu­
dents, language models, and higher education underscore primary 
domains of investigation. Conversely, concepts such as contrastive 
learning, collaborative learning, and technology adoption are peripheral 
and more contemporary, indicating nascent or inadequately investi­
gated avenues. This map facilitates the identification of prevailing 
trends and research deficiencies, guiding future inquiries into the 
intricate influence of ChatGPT on educational practices and policies.
These five themes were identified through thematic synthesis and 
reflect how ChatGPT impacts students across three broad domains: 
cognitive (academic performance, second-language users), emotional 
(mental health), and behavioral (peer pressure, inspiration). This 
structure aligns with our second objective, which examines cognitive, 
emotional, and behavioral impacts in higher education.
Given the wide range of perspectives, a systematic review is essential 
to consolidate research on ChatGPT in education, addressing not only 
academic outcomes and risks but also the often-overlooked cognitive, 
emotional, and behavioral impacts. Fig. 2 outlines the contributions and 
gaps of recent systematic reviews (Baig & Yadegaridehkordi, 2024; Deng 
et al., 2025; Elbaz et al., 2024; García-L´opez et al., 2025; Garg et al., 
2023; G¨odde et al., 2023; Imran & Almusharraf, 2023; Levin et al., 2024; 
Lo, 2023; Lo et al., 2024; Ma et al., 2024; Michel-Villarreal et al., 2023; 
Salih et al., 2025; Sallam, 2023; Vargas-Murillo et al., 2023; Zamfiroiu 
et al., 2023; Zhang & Tur, 2024; ˙Ipek et al., 2023).
Notably, Deng et al. (Deng et al., 2025) synthesized 22 systematic 
reviews and meta-analyses on educational outcomes, while Lo et al. (Lo 
et al., 2024) analyzed 14 detailed empirical studies. While these reviews 
focus on isolated themes, our review offers a more integrated perspec­
tive by connecting cognitive (learning), emotional (wellbeing), and so­
cial (collaboration) aspects. It also highlights interdisciplinary gaps, 
such as the lack of longitudinal data, variability across disciplines, and 
the underexplored role of collaboration.
This review addresses that gap through a uniquely integrated lens, 
synthesizing evidence across three interconnected domains: learning, 
well-being, and collaboration in higher education. Such a comprehen­
sive approach enables a deeper understanding of how ChatGPT is 
reshaping teaching practices, learner experiences, and institutional 
strategies. Importantly, insights from the accompanying bibliometric 
analysis reveal that despite growing interest in ChatGPT, the dimensions 
of well-being and collaboration alongside nuanced learning remain 
significantly underexplored in existing literature. This highlights the 
pressing need for a systematic synthesis that extends beyond conven­
tional outcome measures. To structure this effort, the review articulates 
a clear set of research objectives (Fig. 3a), each supported by corre­
sponding research questions (Fig. 3b). Together, they offer a roadmap 
for examining not just what has been studied, but also what needs to be 
addressed in future research to inform responsible and effective adop­
tion of ChatGPT in higher education.
The remainder of this article is structured as follows: Section 2
provides a brief overview of the adopted methodology and protocol, 
including the inclusion and exclusion criteria, search procedure, selec­
tion method, quality assessment, and data extraction and synthesis. 
Section 3 discusses the key findings, highlighting five key dimensions of 
the impact of ChatGPT in higher education: academic performance, 
mental health, second-language users, peer pressure, and inspiration, 
where the unique benefits and challenges are explored for each, as well 
as a brief description of faculty perspectives in association with these 
five dimensions. Section 4 compares ChatGPT with traditional study 
N. Abdallah et al.                                                                                                                                                                                                                               
Social Sciences & Humanities Open 12 (2025) 101866 
2 


## Page 3

methods. Section 5 presents the main limitations and key biases, while 
concluding remarks and future directions are provided in section 6.
2. Review methodology
A systematic literature review (SLR) was employed to evaluate and 
analyze the existing body of research on the application of ChatGPT in 
higher education. This review was conducted according to the Preferred 
Reporting Items for Systematic Reviews and Meta-Analyses statement 
(PRISMA). The approach followed the framework outlined by Kitchen­
ham et al. (Kitchenham & Charters, 2007), which provides a structured 
methodology for minimizing bias and synthesizing research findings. 
The review process included the development of a review protocol, the 
definition of inclusion and exclusion criteria, the search and selection 
processes, quality assessment, and data extraction and synthesis. Addi­
tionally, the review specifically utilized a thematic qualitative synthesis 
approach, given the significant diversity in methodologies, outcomes, 
and contexts across the included studies, which precluded conducting a 
quantitative meta-analysis.
2.1. Review protocol
The review protocol aimed to reduce potential research bias by 
establishing predefined criteria and a systematic approach for identi­
fying, evaluating, and synthesizing relevant literature. This protocol 
guided the entire review process, ensuring transparency and 
replicability.
2.1.1. Inclusion and exclusion criteria
To ensure the rigor and relevance of the review, well-defined in­
clusion and exclusion criteria were established and systematically 
applied during the study selection process. (a) Eligible studies were 
limited to peer-reviewed research articles published in English between 
January 2023 and mid-October 2024, (b) containing relevant keywords 
within the title, abstract, or keyword sections. (c) the review specifically 
focused on empirical investigations examining the application of 
ChatGPT in higher education settings, including both undergraduate 
and postgraduate learning environments. Studies were excluded (a) if 
they did not represent original research, such as editorials, 
commentaries, opinion pieces, meta-analyses, or grey literature. (b) 
articles published outside the specified timeframe or in languages other 
than English were also omitted. (c) in addition, studies that focused 
exclusively on K–12 education or pre-university diploma programs were 
excluded from consideration, as they fell outside the defined scope of 
this review.
2.1.2. Search procedure
Two authors (NA and RK) independently screened the titles and 
abstracts of potential studies without employing any automation tools. A 
comprehensive search was conducted across several relevant databases, 
including Emerald, ERIC, MDPI, SAGE, Elsevier, SpringerLink, Frontiers, 
PlosOne, Wiley, and Taylor & Francis. Boolean operators were employed 
to maximize the retrieval of relevant studies using search strings such as 
("ChatGPT ") AND ("higher education" OR "university" OR "undergrad­
uate" OR "graduate"). Any disagreements regarding the eligibility of an 
article were resolved through discussion.
2.1.3. Selection process
The selection process is outlined in Fig. 4. The automated search 
phase retrieved a total of 209 studies. After applying the inclusion and 
exclusion criteria, 42 articles remained. A manual search yielded 30 
additional studies, resulting in 72 quality assessments. We excluded 33 
studies due to their low quality, leaving 39 articles for analysis. We 
removed duplicates before screening, and a second reviewer indepen­
dently validated a random subset to reduce bias.
2.1.4. Quality assessment
The quality of the selected studies (EQ) was evaluated using criteria 
adapted from Kitchenham and Charters (Kitchenham & Charters, 2007). 
● EQ1: Does the article explicitly discuss ChatGPT?
● EQ2: Does the article focus on ChatGPT in higher education?
● EQ3: Is the article a research study?
●EQ4: Does the article provide a clear research methodology?
Each study was scored on a scale of 0–2 per criterion (0 = not 
addressed, 1 = partially addressed, 2 = fully addressed), yielding a total 
possible score of 8. We classified studies scoring below 4 as weak, and 
Fig. 1. Keyword co-occurrence network visualization for identifying research gaps in ChatGPT-related higher education studies. Source: Authors.
N. Abdallah et al.                                                                                                                                                                                                                               
Social Sciences & Humanities Open 12 (2025) 101866 
3 


## Page 4

those scoring above 4 as medium or high. while scores above 4 were 
categorized as medium or high. The reviewers independently assessed 
all 72 initially eligible studies. Discrepancies were discussed and 
resolved jointly, ensuring consistency and minimizing bias in the in­
clusion process. As a result of this process, 33 studies were excluded due 
to failing to meet minimum quality standards. The most common issues 
among excluded papers were. 
1. Lack of clearly stated research objectives (EQ1 = 0)
2. Vague or missing methodological descriptions (EQ2 = 0 or 1)
3. Absence of evaluation metrics or outcome data (EQ3 = 0)
4. Editorial or anecdotal commentary without empirical basis (EQ4 =
0)
Fig. 2. Chronological overview of systematic reviews and studies on ChatGPT in higher education (2023–2025). Source: (Deng et al., 2025; Lo et al., 2024).
N. Abdallah et al.                                                                                                                                                                                                                               
Social Sciences & Humanities Open 12 (2025) 101866 
4 


## Page 5

2.1.5. Data extraction and synthesis
The final stage involved extracting data from the remaining 39 
studies. Key information, such as research objectives, methods, results, 
and limitations, was systematically retrieved and tabulated. This process 
facilitated a detailed synthesis, enabling the identification of recurring 
themes, emerging trends, and significant gaps in the literature. Table I
presents a detailed summary of the studies, which includes objectives, 
methodologies, and key findings.
Fig. 3. Overview of research design: (a)objectives formulation and (b) research questions. Source: Authors.
Fig. 4. Diagram illustrating the PRISMA article selection process. Source: Authors.
N. Abdallah et al.                                                                                                                                                                                                                               
Social Sciences & Humanities Open 12 (2025) 101866 
5 


## Page 6

Table 1 
Summary of recent studies on ChatGPT in higher education.
Ref
Year
Objective
Methods
Results
Stadler et al. 
(2024)
2024
Studied cognitive load and learning with LLMs 
in university students.
Students used either ChatGPT or Google to 
research nanoparticles in sunscreen.
LLM users had lower cognitive load but weaker 
reasoning and argumentation.
Huang et al. 
(2023)
2023
Created an AI-based personalized intervention 
for at-risk students.
Students took an 8-week Python course, with 
one group receiving intervention and the 
other not.
The intervention improved learning 
performance, self-regulation, effort regulation, 
and peer learning.
Johnson et al. 
(2024)
2024
Compared novice Arduino programmers who 
wrote their own code (self-programming) with 
those who used ChatGPT 3.5 (ChatGPT 
programming) on task scores, interest, self- 
efficacy, ability, and errors.
Analyzed 33 students in an agricultural 
technology course at the University of 
Arkansas (Fall 2023), randomly assigned to 
self-programming (n = 17) or ChatGPT- 
programming (n = 16).
Both groups scored above 90 % on programming 
tasks with no significant difference in mean 
scores. The ChatGPT group had more perfect 
scores (68.8 % vs. 41.2 %), but errors stemmed 
from incorrect or incomplete queries.
Gao (2024)
2024
Addresses the effects of undergraduate 
students’ test anxiety and academic emotions.
Randomly selected 180 undergraduates from 
Zhejiang Industry & Trade Vocational College 
in 2023 to study test anxiety and academic 
emotions. Eighty students attended a 4-hour 
workshop on using ChatGPT in education.
By semester’s end, the AI group showed 
significantly lower test anxiety, despite no initial 
differences between groups.
Sandu et al. (2024)
2024
Examined ChatGPT’s impact on pedagogy, 
student engagement, and academic 
performance in higher education.
Surveyed 74 data analytics students in 
Australia, analyzing usage, benefits, and 
challenges.
ChatGPT showed medium effects on perceived 
benefits (η2 = 0.173) and challenges (η2 =
0.289). Frequent users saw academic gains, but 
limitations included handling complex queries 
and lack of human interaction.
Sayed et al. (2024)
2024
Examined ChatGPT’s impact on EFL learners’ 
speaking skills, well-being, autonomy, and 
academic buoyancy.
Studied 28 upper-intermediate EFL students in 
Ethiopia using a mixed-methods approach. 
Speaking skills were tested with TOEFL iBT 
scoring, and psychological factors were 
assessed through narrative frames.
Results showed significant improvements in 
speaking, well-being, autonomy, and academic 
buoyancy. ChatGPT provided personalized 
feedback, enhanced skill development, and 
supported emotional needs.
Lee et al. (2022)
2022
Measured and enhanced interaction quality in 
online forums using ML to promote cognitive 
presence and higher-order thinking.
Analyzed discussion data from an edX MOOC 
(CS1301) and a graduate AI course (CS6601) 
using the Community of Inquiry framework. A 
BERT model, fine-tuned for classification, 
achieved 92.5 % accuracy.
Analyzed discussion data from an edX MOOC 
(CS1301) and a graduate AI course (CS6601) 
using the Community of Inquiry framework. A 
BERT model, fine-tuned for classification, 
achieved 92.5 % accuracy.
Zogheib and 
Zogheib (2024)
2024
Investigated factors influencing students’ 
adoption of ChatGPT using TAM, SDT, trust, 
social influence, and personal innovativeness.
Surveyed 150 engineering students on 
perceptions of usefulness, ease of use, 
motivation, trust, and readiness. Analyzed 
data with SPSS 26 and Smart-PLS4.
Findings showed usefulness, ease of use, 
external motivation, and social influence 
significantly influenced adoption, with trust 
playing a key role. Intrinsic motivation had no 
effect, while personal innovativeness strongly 
impacted intention and use. Behavioral 
intention was the strongest predictor of 
adoption.
Chambers and 
Owen (2024)
2024
Evaluated the impact of GenAI chatbots on 
learning outcomes and test anxiety in 
postsecondary students.
Forty psychology students used chatbots for 
exam prep and essay grading. Surveys 
measured their perceptions of comprehension, 
writing, and anxiety
Students reported improved understanding and 
essay structuring, but no significant reduction in 
test anxiety.
Ardyansyah et al. 
(2024)
2024
Examined Indonesian university students’ 
perspectives on using GPTs for chemistry 
learning, focusing on motives, benefits, 
challenges, and ethics.
Used questionnaires, interviews, and usage 
logs in a case study approach, analyzing data 
thematically.
Students valued GPTs for clarity, speed, and 
usefulness but raised concerns about accuracy 
and ethics. They evaluated responses through 
thought stimulation, confirmation, integration, 
paraphrasing, or direct copying.
D. Kim, Nayak, 
et al. (2024)
2024
This pilot study explored ChatGPT’s impact on 
undergraduate engineering students’ lab 
report writing, focusing on rhetorical 
knowledge, critical thinking, conventions, and 
writing processes.
Seven students revised their lab reports using 
ChatGPT. A comparative analysis evaluated 
report quality, while a focus group captured 
their experiences.
Findings highlighted improvements in writing 
quality and structure, with students noting both 
benefits and challenges in using ChatGPT for 
revision
Serhan and 
Welcome (2024)
2024
Examined undergraduate students’ 
perceptions of ChatGPT as a learning tool for 
Calculus, focusing on advantages, 
disadvantages, and classroom engagement.
Sixty-four students participated, providing 
data through a Likert-scale questionnaire and 
open-ended responses. Quantitative and 
qualitative analyses were conducted.
Most students viewed ChatGPT positively, 
reporting improved understanding of concepts 
and increased classroom participation and 
engagement.
Hammoda (2024)
2024
Explored ChatGPT’s role in an 
entrepreneurship course, assisting students in 
forming venture teams.
Three teams used ChatGPT to define roles, 
essential members, and equity splits based on 
prompts, with findings discussed in class. 
Post-intervention surveys assessed 
perceptions.
Students overwhelmingly favored ChatGPT, 
seeing it as a convenient and resourceful tool 
that supported entrepreneurial learning and 
venture creation.
Ngo et al. (2024)
2024
Examined factors influencing students’ 
satisfaction and continued use of ChatGPT in 
education using the Expectation-Confirmation 
Model (ECM).
Collected survey data from 435 students 
across eight Vietnamese universities, 
analyzing four variables using CFA and SEM 
with SPSS 26 and AMOS 24.
Expectation confirmation and perceived 
usefulness positively impacted satisfaction and 
continued use. However, perceived usefulness 
did not directly influence satisfaction, 
suggesting trust and quality play a role. Students 
who found ChatGPT beneficial were more likely 
to keep using it.
Yin et al. (2024)
2024
Investigated emotional responses and intrinsic 
motivation in micro-learning chatbots, 
comparing metacognitive versus neutral 
feedback.
Sixty-two college students were randomly 
assigned to a Metacognitive EC (reflective 
feedback) or Neutral EC (general feedback) 
group. Chatbots guided them through 
greetings, biology content, self-evaluation, 
and feedback.
Both groups experienced mostly positive 
emotions, but the Metacognitive EC group 
reported fewer negative emotions and weaker 
interest-related motivation, suggesting 
metacognitive feedback may not fully enhance 
intrinsic motivation.
(continued on next page)
N. Abdallah et al.                                                                                                                                                                                                                               
Social Sciences & Humanities Open 12 (2025) 101866 
6 


## Page 7

Table 1 (continued)
Ref 
Year 
Objective 
Methods 
Results
Gulati et al. (2024)
2024
Explored factors influencing marketing 
students’ acceptance of ChatGPT, integrating 
system flexibility into the UTAUT model
Surveyed 309 marketing students, analyzing 
habit, performance expectancy, effort 
expectancy, and perceived risk using 
statistical methods.
Habit was the strongest predictor of ChatGPT 
adoption, followed by performance and effort 
expectancy. Perceived risk had no significant 
impact, as students felt in control of their online 
behavior.
Baidoo-Anu et al. 
(2024)
2024
Examined Ghanaian higher education 
students’ perspectives on ChatGPT, focusing on 
benefits and concerns as a learning tool.
Developed and validated the Students’ 
ChatGPT Experiences Scale (SCES) with data 
from 277 students using exploratory and 
confirmatory factor analysis.
Students highlighted academic benefits but 
raised concerns about originality, security, over- 
reliance, and lack of formal training. Usage was 
primarily for assignments and non-academic 
purposes.
Tu (2024)
2024
Explored undergraduates’ conceptions of 
ChatGPT’s roles, functionalities, and 
interactions based on their growth mindsets
Used the draw-a-picture technique to analyze 
perceptions, interaction skills, question types, 
learning achievements, and critical thinking 
tendencies.
Students with different growth mindsets showed 
significant differences in conceptions of learning 
contexts, interaction patterns, and outcomes, 
with distinct variations in engagement and 
critical thinking approaches.
Shim et al. (2023)
2024
Evaluated an experiential chatbot workshop’s 
effectiveness in engagement, competency 
development, and satisfaction among 
undergraduates.
Conducted in Doing Business with A.I. at 
Singapore Management University, non-STEM 
students used Dialog flow to design chatbot 
prototypes with a user-centric approach.
Results showed 90.7 % satisfaction, 81.4 % 
engagement, and 81.3 % reporting moderate to 
high competency. Nearly all (97.7 %) felt the 
workshop met its learning objectives.
¨Oncel et al. (2021)
2021
Examined whether vocabulary knowledge can 
be modeled through linguistic analysis of 
source-based essays to enhance Automated 
Writing Evaluation.
Essays from 106 undergraduates were 
analyzed at descriptive, lexical, syntactic, and 
cohesive levels using NLP tools. Machine 
learning models predicted vocabulary scores 
based on linguistic features.
Models explained 29 % of the variance in 
vocabulary scores, highlighting a link between 
essay characteristics and individual vocabulary 
differences.
Taniguchi et al. 
(2019)
2019
Investigated a language-independent text 
tokenization algorithm to enhance 
multilingual support for the CoI framework.
Compared the performance of a language- 
independent tokenizer with a language- 
dependent one using a real-world dataset, 
assessing classification accuracy for CoI 
indicators.
Results showed comparable performance 
between both tokenizers, supporting the 
feasibility of data-driven tokenization for 
multilingual CoI analysis and setting a 
foundation for future research. 
4o
Neo (2022)
2022
Developed and evaluated the MERLIN Project, 
an AI-driven virtual learning assistant for 
Malaysian university students during COVID- 
19.
MERLIN used NLP to facilitate humanlike 
interactions, aligning course content with 
Mayer’s 12 Multimedia Learning Principles. 
Data from 102 students assessed its 
effectiveness.
Students found the chatbot helpful for learning 
and comprehension, reporting improved 
engagement and retention in online education.
Chen et al. (2024)
2024
Developed and evaluated MsCAEWL, a 
computer-assisted EFL writing system 
providing detailed, semantic-based multi-trait 
feedback.
Utilized neural networks and NLP to align 
with writing feedback theory, ensuring 
continuous, timely, and interactive feedback. 
Effectiveness was tested against AWE models 
and human raters using t-tests.
MsCAEWL outperformed baseline AWE models 
and closely matched human raters in feedback 
accuracy. Results showed significant 
improvements in students’ EFL writing 
proficiency.
Gammoh (2024)
2024
Explored academics’ perspectives on the risks 
of integrating ChatGPT into university 
assignments and proposed mitigation 
strategies.
Conducted semi-structured interviews with 25 
academics from Jordanian universities, using 
thematic analysis to identify key concerns and 
solutions.
Findings highlighted risks such as plagiarism, 
overdependence on AI, reduced critical 
thinking, and lower assignment quality. 
Suggested mitigation strategies included 
plagiarism detection, disciplinary measures, 
awareness campaigns, and clear usage 
guidelines.
Wang et al. (2022)
2022
Developed and evaluated AIteach, a virtual 
case learning system using real hospital records 
and NLP to enhance medical students’ clinical 
thinking.
AIteach processed hospital case data to create 
realistic simulations, allowing students to 
engage in consultations, exams, and data 
analysis. A multi-dimensional evaluation 
system assessed rigor, logic, systematization, 
agility, and knowledge expansion.
Fifteen graduate medical students showed 
significant clinical thinking improvement, with 
test scores increasing from 69.87 to 85.6 (P <
0.01). Logical reasoning improved the most (47 
%). AIteach effectively replicated traditional 
clinical training while overcoming real-world 
constraints.
Dana and Gavril 
(2023)
2023
Examined the psychological implications of 
chatbots through discussions with 10 
psychology students who had prior chatbot 
experiences.
Students shared emotional responses, 
attitudes, behaviors, and ethical concerns 
related to chatbot interactions.
Findings highlighted chatbots’ convenience and 
efficiency but also frustration when needs were 
unmet. Participants reported social and 
emotional connections with chatbots while 
raising concerns about data privacy and the 
potential replacement of human interaction.
Acosta-Enriquez 
et al. (2024)
2024
Analyzed university students’ attitudes toward 
using ChatGPT in academic activities through a 
quantitative, nonexperimental study.
Surveyed 499 participants, examining factors 
influencing their perspectives.
Results showed responsible use, frequent 
intention, and acceptance as strong predictors of 
a positive attitude, while boredom and 
perceived risk were linked to negative attitudes.
Ajlouni et al. 
(2023)
2023
This study aimed to explore undergraduate 
students’ perceptions of the benefits and 
challenges of using ChatGPT in counseling and 
mental health education, focusing on its 
potential to support learning and achieve 
sustainable development goals.
A descriptive quantitative approach was used 
with a purposive sample of 210 students 
enrolled in the counseling and mental health 
program at the University of Jordan, who had 
experience using ChatGPT in their learning.
The study found that 81.9 % of respondents 
perceived ChatGPT as a beneficial learning tool, 
particularly in supporting primary counseling 
skills and therapeutic conditions, while students 
reported moderate challenges and concerns in 
utilizing the technology.
Ngo (2023)
2023
Explored university students’ perceptions of 
ChatGPT for learning, focusing on benefits, 
barriers, and potential solutions.
Collected data from 200 survey responses and 
30 semi-structured interviews
Students had a positive attitude toward 
ChatGPT, citing time savings, diverse 
information access, personalized tutoring, and 
writing support. Key concerns included 
difficulties in assessing source reliability and 
inaccurate citation capabilities.
(continued on next page)
N. Abdallah et al.                                                                                                                                                                                                                               
Social Sciences & Humanities Open 12 (2025) 101866 
7 


## Page 8

2.1.6. Potential biases
Potential biases are inherent in reviewing articles and need to be 
mentioned here. For instance, selection bias was introduced here 
through the exclusion of non-English studies, which may limit the 
generalizability of our findings. Publication bias is another inherent 
factor. Studies reporting positive impacts of ChatGPT may have a higher 
likelihood of publication. Technological bias consists of any bias due to 
differences in internet access and technological familiarity of students 
and institutions, as well as bias in current data sets used to train AI tools. 
Finally, there is certainly a bias with respect to institutional policies due 
Table 1 (continued)
Ref 
Year 
Objective 
Methods 
Results
Liu (2024)
2024
Examined the relationship between writing 
anxiety and ESL students’ intention to use 
ChatGPT as an automated writing evaluation 
tool through the Technology Acceptance 
Model (TAM).
Conducted a cross-sectional study with 639 
undergraduates, analyzing data using 
Structural Equation Modeling (SEM) with 
Partial Least Squares (PLS).
Findings showed that writing anxiety 
significantly influenced perceived ease of use 
and attitude toward ChatGPT, which in turn 
affected students’ intention to adopt it for 
writing evaluation. 
4o
Duong et al. 
(2024)
2024
Investigated the negative impacts of 
compulsive ChatGPT use in higher education, 
examining stressors like loneliness and social 
avoidance, their effect on psychological 
distress, and the moderating role of 
technostress.
Collected data from 2709 students across 16 
Vietnamese universities using a stratified 
random sampling approach and analyzed 
relationships through the stressor-strain- 
outcome model.
Compulsive ChatGPT use was linked to 
increased loneliness, social avoidance, and 
psychological distress, which negatively 
affected life satisfaction and academic 
performance. Technostress worsened 
psychological distress while further diminishing 
students’ well-being and academic success.
Budhathoki et al. 
(2024)
2023
‵Investigated the negative impacts of 
compulsive ChatGPT use in higher education, 
examining stressors like loneliness and social 
avoidance, their effect on psychological 
distress, and the moderating role of 
technostress.
Collected data from 2709 students across 16 
Vietnamese universities using a stratified 
random sampling approach and analyzed 
relationships through the stressor-strain- 
outcome model.
Compulsive ChatGPT use was linked to 
increased loneliness, social avoidance, and 
psychological distress, which negatively 
affected life satisfaction and academic 
performance. Technostress worsened 
psychological distress while further diminishing 
students’ well-being and academic success.
Salah et al. (2024)
2023
Explored university students’ dependency on 
generative AI chatbots, focusing on intrinsic 
motivations, risk perceptions, and the risk of 
over-reliance.
Analyzed interactions and motivations, with 
hypotheses tested against actual user 
behaviors. This is a preprint, not peer 
reviewed.
Findings suggest growing reliance on chatbots, 
fueled by intrinsic motivations like competence 
and relatedness. Risk perceptions seemed to 
increase reliance, indicating a potential over- 
dependence and highlighting AI’s unpredictable 
impact on education.
Abbas et al. (2024)
2024
Investigated the causes and consequences of 
ChatGPT usage among university students, 
focusing on academic performance and 
behavioral outcomes.
Study 1 developed and validated an 8-item 
ChatGPT usage scale (N = 165). Study 2 
employed a three-wave time-lagged design (N 
= 494) to examine workload, time pressure, 
and reward sensitivity as causes, and 
procrastination, memory loss, and academic 
performance as consequences.
Findings showed that higher academic workload 
and time pressure increased ChatGPT use, while 
sensitivity to rewards reduced it. Usage was 
associated with greater procrastination and 
memory loss, leading to lower academic 
performance. Indirect effects linked workload, 
time pressure, and reward sensitivity to these 
outcomes via ChatGPT usage. 
4o
Koltovskaia et al. 
(2024)
2024
Explored how Iranian graduate ESL students in 
STEM fields engaged with ChatGPT for revising 
academic research proposals across behavioral, 
cognitive, and affective dimensions.
Analyzed screencasts, stimulated recall, semi- 
structured interviews, and follow-up surveys 
with six students.
Findings: 
● Behavioral: Students prioritized lower-order 
text concerns, often using a training prompt 
for revisions.
● Cognitive: They noticed and understood 
ChatGPT’s feedback but questioned its 
accuracy.
● Affective: High satisfaction, particularly with 
ChatGPT’s paraphrasing to enhance 
professionalism.
Sajjad (2024)
2024
Investigated whether excessive ChatGPT use in 
academia is beneficial or harmful, using the 
Uses and Gratification Theory to identify 
predictors and moderators.
Surveyed 617 business and management 
students in southern Punjab, Pakistan, 
analyzing the impact of instant gratification 
(IG), academic workload (AW), and social 
isolation (SI) on usage.
Findings showed IG, AW, and SI increased 
ChatGPT use, with positive reinforcement (PR) 
partially mediating these effects. Technological 
literacy (TL) moderated these relationships, 
amplifying the impact of IG, AW, and SI on PR.
Al-kfairy (2024)
2024
Synthesized empirical studies on ChatGPT 
adoption in higher education, identifying key 
influencing factors and research gaps.
Conducted a narrative review of 40 peer- 
reviewed studies, applying thematic analysis 
grounded in TAM, UTAUT, DoI, TOE, and the 
Theory of Planned Behavior.
Findings: 
● Confirmed factors: Hedonic motivation, 
usability, perceived benefits, system 
responsiveness, and relative advantage.
● Mixed effects: Social influence, privacy, 
security, and facilitating conditions.
● Unconfirmed predictors: Technology 
readiness and extrinsic motivation.
Feng et al. (2023)
2024
Examined the relationship between ChatGPT 
usage and online learning burnout, with self- 
control as a mediating factor.
Analyzed data from 505 Chinese college 
students, assessing correlations between 
ChatGPT use, self-control, and burnout levels.
Findings suggest ChatGPT is a double-edged 
sword—enhancing learning accessibility but 
leading to diminished self-control and increased 
burnout when overused. Advocates for balanced 
usage and strategies to strengthen self-control in 
education.
Farhi et al. (2023)
2023
To examine students’ views, concerns, and 
perceived ethical considerations regarding 
ChatGPT usage in education.
Survey data collected from 388 students at 
two universities in Al Ain, UAE, using 
Yamane’s formula; path analysis to test 
hypotheses.
Students perceive ChatGPT as a revolutionary 
tool that significantly impacts their views, 
concerns, and perceived ethics. While it offers 
substantial benefits, concerns about educational 
integrity persist.
N. Abdallah et al.                                                                                                                                                                                                                               
Social Sciences & Humanities Open 12 (2025) 101866 
8 


## Page 9

to variability in academic policies across different countries and cul­
tures. Fig. 5 shows a bar chart of paper distribution by country.
2.1.7. Risk of bias assessment
To further ensure the reliability of our findings, a structured risk of 
bias assessment was conducted on the included studies. We evaluated 
each article for potential selection, performance, and reporting biases, 
adapting a simplified framework from the Cochrane Risk of Bias tool. We 
examined studies for clarity in research questions, transparency in 
methodology, presence of control/comparison groups, and complete­
ness in reporting outcomes. While most studies provided sufficient detail 
to assess Some studies exhibited potential biases due to small sample 
sizes, lack of randomization, or insufficient control of confounding 
variables. These limitations were considered when interpreting the 
overall strength and consistency of the evidence.
3. Discussion
This systematic review identifies five key dimensions of the impact of 
ChatGPT in higher education: academic performance, mental health, 
second-language users, peer pressure, and inspiration. Table II shows 
how many studies fall into each of these categories, and Table III ana­
lyzes how often each theme appears in the studies, showing which areas 
are most common. Each theme reflects unique benefits and challenges, 
offering a comprehensive perspective on the role of ChatGPT in trans­
forming educational practices. Specifically, this thematic structure 
captures three primary types of impacts: cognitive impacts are reflected 
in academic performance and second-language users, addressing how 
ChatGPT influences learning, comprehension, and critical thinking; 
emotional impacts are explored in mental health, highlighting effects on 
stress, anxiety, and confidence; and behavioral impacts are examined 
through peer pressure and inspiration, focusing on usage patterns, peer 
influence, and creative engagement. This section elaborates on each of 
these dimensions, highlighting the literature’s perspectives on associ­
ated advantages and shortcomings.
3.1. Academic performance
This theme primarily represents the cognitive impacts of ChatGPT, 
including enhancements in comprehension, problem-solving, and 
learning efficiency, as well as concerns about reduced critical thinking 
and analytical depth. A clear majority of the reviewed papers (56.4 %) 
report measurable academic gains associated with ChatGPT adoption. 
Multiple studies across engineering, programming and data-analytics 
courses document higher task scores, improved solution accuracy and 
richer formative feedback when students use the tool for step-by-step 
explanations or debugging assistance (Huang et al., 2023; Johnson 
et al., 2024; Sandu et al., 2024; Serhan & Welcome, 2024). These ben­
efits appear strong when ChatGPT is deployed as a supplementary tutor 
that provides personalized support and frees up classroom time for 
deeper discussion. Yet a consistent cautionary thread emerges 
over-reliance on AI-generated answers can erode critical-thinking and 
argument-construction skills (Farrokhnia et al., 2024; Gammoh, 2024; 
Stadler et al., 2024). Several authors note that although cognitive load is 
reduced, students may default to surface-level reasoning or accept 
unverified output, thereby compromising learning depth. Overall, the 
evidence shows that teaching methods, like having students review or 
fix ChatGPT answers, are important to improve performance while still 
keeping strong thinking skills.
3.2. Mental health
This theme reflects the emotional dimension of ChatGPT use, 
capturing both positive effects like reduced anxiety and increased self- 
efficacy, and negative effects such as technostress and emotional fa­
tigue in cases of overreliance. Roughly one quarter of the corpus (15 %) 
links ChatGPT use to reduced test anxiety, increased academic buoyancy 
and greater self-efficacy (Chambers & Owen, 2024; Gao, 2024; Sayed 
et al., 2024). Immediate feedback and on-demand clarification appear to 
lower stress, especially in high-stakes or time-pressured settings. This 
aligns with findings by Elbaz et al. (Elbaz et al., 2024), who explored 
students’ emotional and ethical responses to ChatGPT, reporting that its 
use in Omani higher education contexts influenced not only academic 
confidence but also raised concerns related to morality and stress. 
Conversely, a smaller but noteworthy set of studies highlights a “dark 
side”: compulsive or habitual use correlates with technostress, social 
avoidance and diminished life satisfaction when the tool displaces peer 
or instructor interaction (Duong et al., 2024; Feng et al., 2023; Yin et al., 
2024). The balance of evidence therefore positions ChatGPT as a po­
tential emotional buffer, provided institutions couple access with 
digital-wellbeing guidance, emphasizing moderation and encouraging 
human support networks.
Fig. 5. The global distribution of scientific articles on ChatGPT in higher education is based on the 39 studies (2023–2024). Source: Authors.
N. Abdallah et al.                                                                                                                                                                                                                               
Social Sciences & Humanities Open 12 (2025) 101866 
9 


## Page 10

3.3. Second-language users
The cognitive impact is particularly notable in this theme, as 
ChatGPT supports language comprehension, vocabulary development, 
and communication skills for second-language learners, helping to 
bridge gaps in understanding. About 13 % of studies focus on English-as- 
a-Second-Language (ESL) populations. Most report improvements in 
writing structure, vocabulary range and speaking proficiency when 
learners employ ChatGPT for real-time paraphrasing or pronunciation 
tips (Koltovskaia et al., 2024; Liu, 2024; Sayed et al., 2024). Students 
appreciate the “24/7 language partner” role and the ability to request 
multiple rephrasing until meaning is clear. However, two recurring 
concerns surface: (i) inaccurate or culturally insensitive outputs in lan­
guages with smaller training corpora (Houston & Corrado, 2023), and 
(ii) the risk that continual AI correction blunts autonomous language 
development. Effective instructional designs therefore blend ChatGPT 
with active production tasks in which learners compare their original 
drafts against AI suggestions and justify acceptance or rejection of each 
change.
3.4. Peer pressure
This theme captures a clear behavioral impact, where the decision to 
adopt or heavily rely on ChatGPT is influenced by peer dynamics, 
competition, and the pressure to keep pace with others. Although only 5 
% of papers center explicitly on peer dynamics, social influence 
consistently emerges as a powerful adoption driver. Students report 
feeling compelled to use ChatGPT to keep pace with classmates who 
leverage it for speed or grade advantage (Gulati et al., 2024; Zogheib & 
Zogheib, 2024). This is consistent with findings from Strzelecki et al. 
(Strzelecki, 2024), who highlights that students’ acceptance and use of 
ChatGPT are significantly shaped by perceived usefulness, ease of use, 
and social norms, including the influence of peers in academic settings. 
This competitive uptake amplifies equity gaps where connectivity or 
device access is uneven. Institutional responses cited in the literature 
include campus-wide licenses, mandatory AI-literacy workshops, and 
collaborative assignments that reward transparent sharing of 
prompt-engineering strategies, all aimed at diffusing pressure and pro­
moting equitable participation.
3.5. Inspiration and creativity
This theme represents both a behavioral impact, as students use 
ChatGPT to initiate and guide their creative processes, and a cognitive 
shift, where idea generation and problem-solving are influenced by AI- 
driven suggestions. Roughly one in ten studies investigate ChatGPT as 
a creativity catalyst. Learners credit the tool with breaking writer’s 
block, expanding idea space and offering fresh analogies (Hammoda, 
2024; Salah et al., 2024). Yet the same papers warn that effortless idea 
generation can dampen originality and reduce confidence in 
self-generated concepts. Investigations comparing divergent- and 
convergent-question prompts show that creative gains are greatest when 
Table 2 
Categorization of studies on ChatGPT in higher education based on key themes.
Ref
Academic Performance
Mental Health
Second Language Users
Peer Pressure
Inspiration
Stadler et al. (2024)
✓
​
​
​
​
Huang et al. (2023)
✓
​
​
​
​
Johnson et al. (2024)
✓
​
​
​
​
Gao (2024)
​
✓
​
​
​
Sandu et al. (2024)
✓
​
​
​
​
Sayed et al. (2024)
​
​
✓
​
​
Lee et al. (2022)
✓
​
​
​
​
Zogheib and Zogheib (2024)
​
​
​
✓
​
Chambers and Owen (2024)
​
​
​
​
✓
Ardyansyah et al. (2024)
✓
​
​
​
​
D. Kim, Nayak, et al. (2024)
✓
​
​
​
​
Serhan and Welcome (2024)
✓
​
​
​
​
Hammoda (2024)
​
​
​
​
✓
Ngo et al. (2024)
​
​
​
✓
​
Yin et al. (2024)
​
✓
​
​
​
Gulati et al. (2024)
✓
​
​
​
​
Baidoo-Anu et al. (2024)
✓
​
​
​
​
Tu (2024)
​
​
✓
​
​
Shim et al. (2023)
​
​
​
​
✓
¨Oncel et al. (2021)
✓
​
​
​
​
Taniguchi et al. (2019)
✓
​
​
​
​
Neo (2022)
✓
​
​
​
​
Chen et al. (2024)
​
​
✓
​
​
Gammoh (2024)
✓
​
​
​
​
Acosta-Enriquez et al. (2024)
✓
​
​
​
​
Ajlouni et al. (2023)
​
✓
​
​
​
Ngo (2023)
✓
​
✓
​
​
Liu (2024)
​
​
​
​
​
Salah et al. (2024)
​
✓
​
​
​
Abbas et al. (2024)
✓
​
​
​
​
Koltovskaia et al. (2024)
✓
​
✓
​
​
Sajjad (2024)
✓
✓
​
​
​
Al-kfairy (2024)
✓
​
​
​
✓
Feng et al. (2023)
✓
✓
​
​
​
Farhi et al. (2023)
✓
​
​
​
​
Table 3 
Frequency and percentage of included studies categorized by key themes related 
to ChatGPT’s impact in higher education.
Theme
Number of Studies
Percentage (%)
Academic Performance
22
56.4 %
Mental Health
6
15.4 %
Second-Language Users
5
12.8 %
Peer Pressure
2
5.1 %
Inspiration & Creativity
4
10.3 %
N. Abdallah et al.                                                                                                                                                                                                                               
Social Sciences & Humanities Open 12 (2025) 101866 
10 


## Page 11

students iteratively refine AI suggestions rather than accepting first-pass 
outputs (Leung & Lo, 2024). Effective practice therefore frames 
ChatGPT as a brainstorming partner whose contributions must be 
critiqued, remixed and properly attributed.
3.6. Integrated insights and research gaps
In summary, cognitive impacts include enhanced comprehension, 
faster learning, and concerns about reduced critical thinking. Emotional 
impacts are reflected in reduced anxiety, stress management, and con­
fidence boosts, balanced by the risk of technostress. Behavioral impacts 
are seen in usage patterns shaped by peer influence, reliance habits, and 
AI-driven creative workflows. Across themes, two broad patterns 
converge. 
• Value-add through personalization and immediacy, ChatGPT excels 
at micro-scaffolded guidance, anxiety reduction, and multilingual 
support.
• Risk of skill atrophy through over-reliance, critical thinking, deep 
reading and original ideation can suffer when AI responses are taken 
at face value.
Notably absent are longitudinal studies tracking sustained learning 
habits and controlled comparisons that isolate ChatGPT’s incremental 
effect over existing digital tools. Future work should also examine dif­
ferential impacts across disciplines with distinct epistemic practices (e. 
g., humanities vs. STEM) and investigate institutional policies that bal­
ance innovation with integrity.
Collectively, the evidence positions ChatGPT as a double-edged 
pedagogical innovation: a potent enhancer of accessibility, feedback 
and learner confidence when embedded within reflective, ethically 
grounded curricula; a potential detractor when used as a shortcut that 
circumvents cognitive effort. Educators, technologists and policymakers 
must therefore co-design guidelines that harness their strengths while 
safeguarding core academic values.
3.7. Ethical and policy considerations
Several studies in this review briefly acknowledge the ethical and 
policy implications of ChatGPT’s integration into higher education, 
although few address them in depth. The main worries often mentioned 
are about academic integrity, where using AI-generated answers could 
harm the fairness of assessments if they are misused for cheating or 
getting help without giving credit (as Elbaz et al. (Elbaz et al., 2024)). 
Others highlight data privacy and surveillance, particularly in institu­
tional contexts where AI tools are embedded into learning platforms that 
collect student inputs.
The model may show algorithmic bias, especially in places that are 
not English-speaking or are culturally diverse, by a lack of representa­
tion or produce stereotypical results (Michel-Villarreal et al. 
(Michel-Villarreal et al., 2023)). Furthermore, digital equity is discussed 
in studies focused on global South contexts, where disparities in access 
and digital literacy may lead to unequal academic outcomes.
To address these issues, a few papers propose guidelines such as 
promoting AI literacy, setting transparent usage policies, and encour­
aging critical engagement with AI outputs (Michel-Villarreal et al., 
2023; Strzelecki, 2024). However, most authors agree that clearer 
institutional frameworks are needed to balance innovation with fairness, 
privacy, and academic standards (Elbaz et al., 2024). A more robust 
ethical discussion in future studies is essential to help educators and 
policymakers ensure the responsible use of AI in higher education.
4. ChatGPT versus traditional study methods
The integration of ChatGPT in higher education has introduced new 
dynamics in student learning, faculty strategies, and the experience of 
second-language learners. This section explores how ChatGPT compares 
to traditional study methods, its multifaceted roles for students, strate­
gies for faculty to address critical thinking challenges, and its impact on 
second-language students. The adoption of ChatGPT has transformed 
traditional study methods, offering students immediate access to infor­
mation and personalized assistance (Johnson et al., 2024). Unlike con­
ventional methods that rely heavily on textbooks, lectures, and peer 
discussions, ChatGPT provides instant explanations and clarifications, 
improving the learning process. However, this convenience may come at 
the cost of reduced engagement with material and diminished critical 
thinking. Over-reliance on AI tools might hinder deep comprehension 
and problem-solving skills (H. K. Kim, Nayak, et al., 2024).
4.1. ChatGPT as a personalized tutor, counselor, interpreter, mentor, and 
friend
Beyond serving as an academic assistant, ChatGPT has been used in a 
variety of supportive roles for students, including acting as a tutor by 
offering explanations and guidance on academic subjects, a counselor by 
providing stress-relief strategies and time-management tips, an inter­
preter by assisting non-native speakers in understanding and translating 
content, a mentor by guiding career planning and personal develop­
ment, and even as a friend through casual conversation and compan­
ionship (Acosta-Enriquez et al., 2024; Taniguchi et al., 2019). This 
multifaceted functionality can enhance the student experience by of­
fering support across both academic and personal domains; however, it 
may also increase students’ over-reliance on emotional support, poten­
tially impacting their social development.
4.2. Critical thinking and academic resilience
The ease of access to information through ChatGPT may discourage 
students from deep engagement and critical analysis. To mitigate this, 
faculty can adopt several strategies. One approach is to promote active 
learning by encouraging methods that require students to analyze, 
evaluate, and create, thereby fostering deeper understanding. Another 
strategy involves integrating assignments that ask students to critique 
the accuracy and reliability of ChatGPT-generated content, which helps 
sharpen their evaluative skills (Stadler et al., 2024; D. Kim, Nayak, et al., 
2024). Additionally, setting clear guidelines on the appropriate use of 
AI, emphasizing its role as a supplementary aid rather than a primary 
source, can help frame its purpose more effectively. Finally, offering 
workshops on digital literacy can educate students about both the 
strengths and limitations of AI tools, encouraging informed and 
responsible use.
4.3. ChatGPT’s role and second-language students
For students learning in a non-native language, ChatGPT serves as a 
valuable resource by assisting with language clarification, helping them 
understand complex terminology and idiomatic expressions. It also 
supports writing improvement through grammar and style suggestions, 
aiding in the development of stronger writing skills. Additionally, it 
offers pronunciation guidance, providing phonetic assistance to enhance 
spoken language proficiency. While these features can significantly 
support language acquisition, it is crucial for students to balance AI 
assistance with active language practice to ensure comprehensive skill 
development.
4.4. Key research findings
Aligned with the six research questions (RQ1–RQ6) shown in Fig. 3b, 
key findings from the reviewed studies are summarized in Fig. 6. For 
RQ1 (Academic Performance), multiple studies report that ChatGPT 
supports learning by offering personalized feedback, clarifying complex 
topics, and improving writing and reading skills. However, some studies 
N. Abdallah et al.                                                                                                                                                                                                                               
Social Sciences & Humanities Open 12 (2025) 101866 
11 


## Page 12

warn that unguided use may encourage surface-level learning and 
reduce critical thinking (Huang et al., 2023; Sandu et al., 2024). These 
mixed results likely reflect differences in usage strategies, learner pro­
files, and context.
Regarding RQ2 (well-being), ChatGPT can ease academic anxiety but 
raises concerns about overdependence and reduced motivation, espe­
cially under stress. Likewise, RQ3 (second -language learners) shows 
ChatGPT helps improve academic voice and engagement through better 
grammar, content refinement, and writing fluency. For RQ4 (Peer 
Pressure), peer influence plays a major role in adoption. Students often 
follow peer trends more than institutional rules. Moreover, RQ5 (Crea­
tivity and Inspiration) highlights ChatGPT’s value as a brainstorming 
tool that supports divergent thinking and creative exploration when 
used interactively. Finally, RQ6 (Ethical and Policy Implications) raises 
concerns about academic integrity, authorship, and access equity. Most 
studies recommend clear institutional guidelines and digital literacy 
training to ensure responsible use.
Fig. 6. Key Findings based on Research Questions. Source: Authors.
N. Abdallah et al.                                                                                                                                                                                                                               
Social Sciences & Humanities Open 12 (2025) 101866 
12 


## Page 13

5. Conclusions and future directions
Our review underscores ChatGPT’s growing influence in higher ed­
ucation, offering clear benefits such as enhanced learning, reduced 
anxiety, and fast personalized feedback. Its popularity among students 
positions it as a powerful academic tool. However, concerns remain 
around over-reliance, reduced critical thinking, academic integrity, and 
equity issues. These challenges highlight the need for thoughtful inte­
gration supported by ethical guidelines, AI literacy, and multidisci­
plinary collaboration. Institutions must adopt balanced strategies that 
promote ChatGPT’s strengths while addressing its risks. This includes 
training educators and students on ethical use, developing culturally 
sensitive AI frameworks, and tailoring adoption across academic disci­
plines. The global scope of reviewed studies adds valuable insights but 
also introduces limitations due to varying methods, contexts, and 
languages.
Future research should include longitudinal studies to assess long- 
term impacts on learning and critical thinking. Greater focus is also 
needed on underrepresented regions, emotional well-being, and 
discipline-specific applications. Robust, transparent frameworks are 
essential to ensure responsible use that prioritizes academic integrity 
and inclusivity. As AI continues to shape education, ongoing research 
and policy development will be key to ensuring that tools like ChatGPT 
enhance, not replace, the core values of higher education.
CRediT authorship contribution statement
Naya Abdallah: Writing – original draft, Conceptualization. Rateb 
Katmah: Writing – review & editing, Investigation. Kinda Khalaf: 
Writing – review & editing, Supervision. Herbert F. Jelinek: Writing – 
review & editing, Supervision.
Data availability statement
This is a review article. All data analyzed in this study are from 
previously published studies, which are cited in the references. No new 
data were generated.
Declaration of the use of AI assisted technologies
During the preparation of this work the authors used ChatGPT for 
proof reading and spell checking. The authors reviewed and edited the 
content as needed and take full responsibility for the content of the 
publication.
Funding statement
This work was supported by Healthcare Engineering Innovation 
Group of Khalifa University.
Declaration of competing interest
The authors declare that they have no known competing financial 
interests or personal relationships that could have appeared to influence 
the work reported in this paper.
References
Abbas, M., Jam, F. A., & Khan, T. I. (2024). Is it harmful or helpful? Examining the causes 
and consequences of generative AI usage among university students. International 
journal of educational technology in higher education, 21(1), 10. https://doi.org/ 
10.1186/s41239-024-00444-7
Acosta-Enriquez, B. G., Arbulú Ballesteros, M. A., Huamaní Jordan, O., L´opez Roca, C., & 
Saavedra Tirado, K. (2024). Analysis of college students’ attitudes toward the use of 
ChatGPT in their academic activities: effect of intent to use, verification of 
information and responsible use. BMC psychology, 12(1), 255. https://doi.org/ 
10.1186/s40359-024-01764-z
Ajlouni, A., Almahaireh, A., & Whaba, F. (2023). Students’ perception of using ChatGPT 
in counseling and mental health education: The benefits and challenges. International 
Journal of Emerging Technologies in Learning (iJET), 18(20), 199–218. https://doi.org/ 
10.3991/ijet.v18i20.42075
Al-kfairy, M. (2024). Factors impacting the adoption and acceptance of ChatGPT in 
educational settings: A narrative review of empirical studies. Applied System 
Innovation, 7(6), 110. https://doi.org/10.3390/asi7060110
AlAfnan, M. A., Dishari, S., Jovic, M., & Lomidze, K. (2023). Chatgpt as an educational 
tool: Opportunities, challenges, and recommendations for communication, business 
writing, and composition courses. Journal of Artificial Intelligence and Technology, 3 
(2), 60–68. https://doi.org/10.37965/jait.2023.0184
Ardyansyah, A., Yuwono, A. B., Rahayu, S., Alsulami, N. M., & Sulistina, O. (2024). 
Students’ perspectives on the application of a generative pre-trained transformer 
(GPT) in chemistry learning: A case study in Indonesia. Journal of Chemical 
Education, 101(9), 3666–3675. https://doi.org/10.1021/acs.jchemed.4c00220
Baidoo-Anu, D., Asamoah, D., Amoako, I., & Mahama, I. (2024). Exploring student 
perspectives on generative artificial intelligence in higher education learning. 
Discover Education, 3(1), 98. https://doi.org/10.1007/s44217-024-00173-z
Baig, M. I., & Yadegaridehkordi, E. (2024). ChatGPT in the higher education: A 
systematic literature review and research challenges. International Journal of 
Educational Research, 127, Article 102411. https://doi.org/10.1016/j. 
ijer.2024.102411
Budhathoki, T., Zirar, A., Njoya, E. T., & Timsina, A. (2024). ChatGPT adoption and 
anxiety: A cross-country analysis utilising the unified theory of acceptance and use of 
technology (UTAUT). Studies in Higher Education, 1–16. https://doi.org/10.1080/ 
03075079.2024.2333937
Chambers, L., & Owen, W. J. (2024). The efficacy of GenAI tools in postsecondary 
education. Brock Education Journal, 33(3), 57–74. https://doi.org/10.26522/ 
brocked.v33i3.1178
Chen, B., Bao, L., Zhang, R., Zhang, J., Liu, F., Wang, S., & Li, M. (2024). A multi-strategy 
computer-assisted EFL writing learning system with deep learning incorporated and 
its effects on learning: A writing feedback perspective. Journal of Educational 
Computing Research, 61(8), 60–102. https://doi.org/10.1177/07356331231189294
Crawford, J., Allen, K.-A., Pani, B., & Cowling, M. (2024). When artificial intelligence 
substitutes humans in higher education: The cost of loneliness, student success, and 
retention. Studies in Higher Education, 49(5), 883–897. https://doi.org/10.1080/ 
03075079.2024.2326956
Dana, R., & Gavril, R. (2023). Exploring the psychological implications of chatGPT: A 
qualitative study. Journal of Education, 32(1), 43–55. https://doi.org/10.24250/jpe/ 
Vol.321/2023/DR/GR
Deng, R., Jiang, M., Yu, X., Lu, Y., & Liu, S. (2025). Does ChatGPT enhance student 
learning? A systematic review and meta-analysis of experimental studies. Computers 
& Education, 227, Article 105224. https://doi.org/10.1016/j.compedu.2024.105224
Duong, C. D., Vu, T. N., Ngo, T. V. N., Do, N. D., & Tran, N. M. (2024). Reduced student 
life satisfaction and academic performance: Unraveling the dark side of ChatGPT in 
the higher education context. International Journal of Human-Computer Interaction, 
1–16. https://doi.org/10.1080/10447318.2024.2356361
Elbaz, A. M., Salem, I. E., Darwish, A., Alkathiri, N. A., Mathew, V., & Al-Kaaf, H. A. 
(2024). Getting to know ChatGPT: How business students feel, what they think about 
personal morality, and how their academic outcomes affect Oman’s higher 
education. Computers and Education: Artificial Intelligence, 7, Article 100324. https:// 
doi.org/10.1016/j.caeai.2024.100324
Farhi, F., Jeljeli, R., Aburezeq, I., Dweikat, F. F., Al-shami, S. A., & Slamene, R. (2023). 
Analyzing the students’ views, concerns, and perceived ethics about chat GPT usage. 
Computers and Education: Artificial Intelligence. , Article 100180. https://doi.org/ 
10.1016/j.caeai.2023.100180
Farrokhnia, M., Banihashem, S. K., Noroozi, O., & Wals, A. (2024). A SWOT analysis of 
ChatGPT: Implications for educational practice and research. Innovations in Education 
& Teaching International, 61(3), 460–474. https://doi.org/10.1080/ 
14703297.2023.2195846
Feng, M., Xia, A., & Xia, X. (2023). The association between ChatGPT usage and college 
students’ online learning burnout: The mediating role of self-control. Paper presented 
at the 2023 Twelfth International Conference of Educational Innovation through 
Technology (EITT). https://doi.org/10.1109/EITT61659.2023.00046
Gammoh, L. A. (2024). ChatGPT in academia: Exploring university students’ risks, 
misuses, and challenges in Jordan. Journal of Further and Higher Education, 48(6), 
608–624. https://doi.org/10.1080/0309877X.2024.2378298
Gao, S. (2024). Can artificial intelligence give a hand to open and distributed learning? A 
probe into the state of undergraduate students’ academic emotions and test anxiety 
in learning via ChatGPT. International Review of Research in Open and Distributed 
Learning, 25(3), 199–218. https://doi.org/10.19173/irrodl.v25i3.7742
García-L´opez, I. M., Gonz´alez, C. S. G., Ramírez-Montoya, M.-S., & Molina-Espinosa, J.- 
M. (2025). Challenges of implementing ChatGPT on education: Systematic literature 
review. International Journal of Educational Research Open, 8, Article 100401. https:// 
doi.org/10.1016/j.ijedro.2024.100401
Garg, R. K., Urs, V. L., Agarwal, A. A., Chaudhary, S. K., Paliwal, V., & Kar, S. K. (2023). 
Exploring the role of ChatGPT in patient care (diagnosis and treatment) and medical 
research: A systematic review. Health Promotion Perspectives, 13(3), 183. https://doi. 
org/10.34172/hpp.2023.22
G¨odde, D., N¨ohl, S., Wolf, C., Rupert, Y., Rimkus, L., Ehlers, J., … Sellmann, T. (2023). 
A SWOT (strengths, weaknesses, opportunities, and threats) analysis of ChatGPT in 
the medical literature: concise review. Journal of Medical Internet Research, 25, 
Article e49368. https://doi.org/10.2196/49368
Gulati, A., Saini, H., Singh, S., & Kumar, V. (2024). Enhancing learning potential: 
Investigating marketing students’behavioral intentions to adopt chatgpt. Marketing 
Education Review, 1–34. https://doi.org/10.1080/10528008.2023.2300139
N. Abdallah et al.                                                                                                                                                                                                                               
Social Sciences & Humanities Open 12 (2025) 101866 
13 


## Page 14

Hammoda, B. (2024). ChatGPT for founding teams: An entrepreneurial pedagogical 
innovation. International Journal of Technology in Education, 7(1), 154–173. https:// 
doi.org/10.46328/ijte.530
Houston, A. B., & Corrado, E. M. (2023). Embracing ChatGPT: Implications of emergent 
language models for academia and libraries. Technical Services Quarterly, 40(2), 
76–91. https://doi.org/10.1080/07317131.2023.2187110
Huang, A. Y., Chang, J. W., Yang, A. C., Ogata, H., Li, S. T., Yen, R. X., & Yang, S. J. 
(2023). Personalized intervention based on the early prediction of At-risk students to 
improve their learning performance. Educational Technology & Society, 26(4), 69–89. 
https://www.jstor.org/stable/48747521.
Imran, M., & Almusharraf, N. (2023). Analyzing the role of ChatGPT as a writing 
assistant at higher education level: A systematic review of the literature. 
Contemporary Educational Technology, 15(4), Article ep464. https://doi.org/ 
10.30935/cedtech/13605
˙Ipek, Z. H., G¨ozüm, A. I. C., Papadakis, S., & Kallogiannakis, M. (2023). Educational 
applications of the ChatGPT AI system: A systematic review research. Educational 
Process: International Journal, 12(3), 26–55. https://doi.org/10.22521/ 
edupij.2023.123.2
Johnson, D. M., Doss, W., & Estepp, C. M. (2024). Using ChatGPT with novice arduino 
programmers: Effects on performance, interest, self-efficacy, and programming 
ability. Journal of Research in Technical Careers, 8(1), 1. https://doi.org/10.9741/ 
2578-2118.1152
Kim, D., Majdara, A., & Olson, W. (2024). A pilot study inquiring into the impact of 
ChatGPT on lab report writing in introductory engineering labs. International Journal 
of Technology in Education, 7(2), 259–289. https://doi.org/10.46328/ijte.691
Kitchenham, B., & Charters, S. (2007). Guidelines for performing systematic literature 
reviews in software engineering. UK https://docs.edtechhub.org/lib/EDAG684W.
Koltovskaia, S., Rahmati, P., & Saeli, H. (2024). Graduate students’ use of ChatGPT for 
academic text revision: Behavioral, cognitive, and affective engagement. Journal of 
Second Language Writing, 65, Article 101130. https://doi.org/10.1016/j. 
jslw.2024.101130
Lee, J., Soleimani, F., Hosmer IV, J., Soylu, M. Y., Finkelberg, R., & Chatterjee, S. (2022). 
Predicting cognitive presence in At-Scale online learning: MOOC and for-credit 
online course environments. Online Learning, 26(1), 58–79. https://doi.org/ 
10.24059/olj.v26i1.3060
Leung, R., & Lo, I. S. (2024). Can chatgpt inspire me? Evaluate students’ questioning 
techniques on ai tool for overcoming fixation. Paper presented at the ENTER e-Tourism 
Conference. https://doi.org/10.1007/978-3-031-58839-6_9
Levin, G., Horesh, N., Brezinov, Y., & Meyer, R. (2024). Performance of ChatGPT in 
medical examinations: A systematic review and a meta-analysis. BJOG: An 
International Journal of Obstetrics & Gynaecology, 131(3). https://doi.org/10.1111/ 
1471-0528.17641
Liu, Z. (2024). Second language writing anxiety and ChatGPT adoption as an automated 
writing evaluation tool. Journal of Applied Research in Higher Education. https://doi. 
org/10.1108/JARHE-06-2024-0260
Lo, C. K. (2023). What is the impact of ChatGPT on education? A rapid review of the 
literature. Education Sciences, 13(4), 410. https://doi.org/10.3390/educsci13040410
Lo, C. K., Hew, K. F., & Jong, M. S.-y. (2024). The influence of ChatGPT on student 
engagement: A systematic review and future research agenda. Computers & 
Education. , Article 105100. https://doi.org/10.1016/j.compedu.2024.105100
Ma, Q., Crosthwaite, P., Sun, D., & Zou, D. (2024). Exploring ChatGPT literacy in 
language education: A global perspective and comprehensive approach. Computers 
and Education: Artificial Intelligence, 7, Article 100278. https://doi.org/10.1016/j. 
caeai.2024.100278
Michel-Villarreal, R., Vilalta-Perdomo, E., Salinas-Navarro, D. E., Thierry-Aguilera, R., & 
Gerardou, F. S. (2023). Challenges and opportunities of generative AI for higher 
education as explained by ChatGPT. Education Sciences, 13(9), 856. https://doi.org/ 
10.3390/educsci13090856
Neo, M. (2022). The merlin project: MALAYSIAN STUDENTS’ACCEPTANCE of an AI 
chatbot in their learning process. The Turkish Online Journal of Distance Education, 23 
(3), 31–48. https://doi.org/10.17718/tojde.1137122
Ngo, T. T. A. (2023). The perception by university students of the use of ChatGPT in 
education. International Journal of Emerging Technologies in Learning (Online), 18(17), 
4. https://doi.org/10.3991/ijet.v18i17.39019
Ngo, T. T. A., An, G. K., Nguyen, P. T., & Tran, T. T. (2024). Unlocking educational 
potential: Exploring students’ satisfaction and sustainable engagement with 
ChatGPT using the ECM model. Journal of Information Technology Education: 
Research, 23, 21. https://doi.org/10.28945/5344
¨Oncel, P., Flynn, L. E., Sonia, A. N., Barker, K. E., Lindsay, G. C., McClure, C. M., … 
Allen, L. K. (2021). Automatic student writing evaluation: Investigating the impact 
of individual differences on source-based writing. Paper presented at the LAK21: 11th 
international learning analytics and knowledge conference. https://doi.org/10.1145/ 
3448139.3448207
Rawas, S. (2024). ChatGPT: Empowering lifelong learning in the digital age of higher 
education. Education and Information Technologies, 29(6), 6895–6908. https://doi. 
org/10.1007/s10639-023-12114-8
Sajjad, M. (2024). Curse or a blessing: Excessive use of ChatGPT in academia. Bulletin of 
Business and Economics (BBE), 13(2), 290–297. https://doi.org/10.61506/01.00329
Salah, M., Abdelfattah, F., Alhalbusi, H., & Al Mukhaini, M. (2024). Me and my AI bot: 
Exploring the’AIholic’Phenomenon and university students’ dependency on generative AI 
Chatbots-Is this the new academic addiction?. https://doi.org/10.21203/rs.3.rs- 
3508563/v1
Salih, S., Husain, O., Hamdan, M., Abdelsalam, S., Elshafie, H., & Motwakel, A. (2025). 
Transforming education with AI: A systematic review of ChatGPT’s role in learning, 
academic practices, and institutional adoption. Results in Engineering, 25, Article 
103837. https://doi.org/10.1016/j.rineng.2024.103837
Sallam, M. (2023). ChatGPT utility in healthcare education, research, and practice: 
Systematic review on the promising perspectives and valid concerns. Paper presented 
at the Healthcare. https://doi.org/10.3390/healthcare11060887
Sandu, R., Gide, E., & Elkhodr, M. (2024). The role and impact of ChatGPT in educational 
practices: Insights from an Australian higher education case study. Discover 
Education, 3(1), 71. https://doi.org/10.1007/s44217-024-00126-6
Sayed, B. T., Bani Younes, Z. B., Alkhayyat, A., Adhamova, I., & Teferi, H. (2024). To be 
with artificial intelligence in oral test or not to be: A probe into the traces of success 
in speaking skill, psychological well-being, autonomy, and academic buoyancy. 
Language Testing in Asia, 14(1), 49. https://doi.org/10.1186/s40468-024-00321-0
Serhan, D., & Welcome, N. (2024). Integrating ChatGPT in the calculus classroom: 
Student perceptions. International Journal of Technology in Education and Science, 8 
(2), 325–335. https://doi.org/10.46328/ijtes.559
Shim, K. J., Menkhoff, T., Teo, L. Y. Q., & Ong, C. S. Q. (2023). Assessing the effectiveness 
of a chatbot workshop as experiential teaching and learning tool to engage 
undergraduate students. Education and Information Technologies, 28(12), 
16065–16088. https://doi.org/10.1007/s10639-023-11795-5
Singh, S. (2025). ChatGPT statistics (april 2025): Number of Users & queries. Retrieved 
from https://www.demandsage.com/chatgpt-statistics/.
Stadler, M., Bannert, M., & Sailer, M. (2024). Cognitive ease at a cost: LLMs reduce 
mental effort but compromise depth in student scientific inquiry. Computers in 
Human Behavior, 160, Article 108386. https://doi.org/10.1016/j.chb.2024.108386
Strzelecki, A. (2024). To use or not to use ChatGPT in higher education? A study of 
students’ acceptance and use of technology. Interactive Learning Environments, 32(9), 
5142–5155. https://doi.org/10.1080/10494820.2023.2209881
Taniguchi, Y., Konomi, S. I., & Goda, Y. (2019). Examining language-agnostic methods of 
automatic coding in the community of inquiry framework. International Association 
for Development of the Information Society. https://doi.org/10.33965/celda2019_ 
201911L003
Tu, Y.-F. (2024). Roles and functionalities of ChatGPT for students with different growth 
mindsets. Educational Technology & Society, 27(1), 198–214. https://www.jstor.org/ 
stable/48754851.
Vargas-Murillo, A. R., de la Asuncion, I., & de Jesús Guevara-Soto, F. (2023). Challenges 
and opportunities of AI-assisted learning: A systematic literature review on the 
impact of ChatGPT usage in higher education. International Journal of Learning, 
Teaching and Educational Research, 22(7), 122–135. https://doi.org/10.4018/ 
IJTEE.343528
Wang, M., Sun, Z., Jia, M., Wang, Y., Wang, H., Zhu, X., … Ji, H. (2022). Intelligent 
virtual case learning system based on real medical records and natural language 
processing. BMC Medical Informatics and Decision Making, 22(1), 60. https://doi.org/ 
10.1186/s12911-022-01797-7
Yin, J., Goh, T.-T., & Hu, Y. (2024). Interactions with educational chatbots: The impact of 
induced emotions and students’ learning motivation. International journal of 
educational technology in higher education, 21(1), 47. https://doi.org/10.1186/ 
s41239-024-00480-3
Zamfiroiu, A., Vasile, D., & Savu, D. (2023). ChatGPT–a systematic review of published 
research papers. Informatica Economica, 27(1), 5–16. https://doi.org/10.24818/ 
issn14531305/27.1.2023.01
Zhang, P., & Tur, G. (2024). A systematic review of ChatGPT use in K-12 education. 
European Journal of Education, 59(2), Article e12599. https://doi.org/10.1111/ 
ejed.12599
Zogheib, S., & Zogheib, B. (2024). Understanding university students’ adoption of 
ChatGPT: Insights from TAM, SDT, and beyond. Journal of Information Technology 
Education: Research, 23, 25. https://doi.org/10.28945/5377
N. Abdallah et al.                                                                                                                                                                                                                               
Social Sciences & Humanities Open 12 (2025) 101866 
14 


---

## Notes
- Auto-converted from PDF
- Please review and clean up formatting as needed
- Add manual annotations and summaries above this line
